{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA on digits.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/duakaran96/ML-AcadView/blob/master/PCA_on_digits.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "S9jMssW0valL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis\n",
        "\n",
        "[Principal component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. \n",
        "\n",
        "In this project we'll take the preloaded *digits* dataset under **scikit-learn** library and will try to reduce the dimensions taking care that our data is not lost.\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "rfUvK_MUqZrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgV51MLjwrkb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The code below will load digits datset"
      ]
    },
    {
      "metadata": {
        "id": "Hn_lQPgrqiP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLy92thnqqAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "digits = load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_fdvhXlTwxcc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Separating the features and target into X and y"
      ]
    },
    {
      "metadata": {
        "id": "-YtVhv6vqrub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = digits.data\n",
        "y = digits.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Csv6LRTnw4_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scaling the features on a standard scale using StandardScaler"
      ]
    },
    {
      "metadata": {
        "id": "QAWRXoyGqtZv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ev0DxDRVqvj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCqlZGArqx-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d00c944-93ea-4db2-ba87-a963be469f16"
      },
      "cell_type": "code",
      "source": [
        "scaler.fit(X)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "CzYs6An6q0DZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = scaler.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuUf-tqpxBJd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "metadata": {
        "id": "zPAvsLAeq2T_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnpZCAxjq460",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U_crPKN0xEVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building and Training Our Logistic Regression Model"
      ]
    },
    {
      "metadata": {
        "id": "AR9Y3cLKq7aM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtwApUR7q-Sw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fSTIcN_erA7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fab9206-2650-4b9c-a99a-b35f3e85d91a"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "log.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.14958953857421875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-uj3-Ubjx-dX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We directly passed our data into Logistic regression Model and the fitting time came out to be as above.\n",
        "\n",
        "Our data had 64 Dimensions in it.\n",
        "\n",
        "Let's take a look at **Predictions** and **accuracy score**"
      ]
    },
    {
      "metadata": {
        "id": "qUkqtzfWrn_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = log.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQiQzoYtrr2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCSeZrQir8Y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24ee30fc-611b-46e4-dda9-4432a79a49e8"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy Score when directly doing logistic regression', accuracy_score(y_test, predictions))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score when directly doing logistic regression 0.9707927677329624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9hoD05GXyegf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll try to do **Dimnsionality Reduction** and take out **Principal Components** so as to optimize for the fitting time for our algorithm and to reduce the memory usage.\n",
        "\n",
        "## Importing PCA from decomposition class under sklearn"
      ]
    },
    {
      "metadata": {
        "id": "AmOS9y3VsKa-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q62hIT97zDFV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We want principal components to retain the 99% of variance described by our data.\n",
        "\n",
        "We fit the pca onto our training data, which is the general practice to do that, because in real life scenarios we do not have testing data beforehand."
      ]
    },
    {
      "metadata": {
        "id": "wdOlAnyIsfjB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pca = PCA(.99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPEHrw8rtDuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "998d8586-ba2a-45fd-adcf-b45e60c1aacf"
      },
      "cell_type": "code",
      "source": [
        "pca.fit(X_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
              "  svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "wcl4lnZ-y8VD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transforming our training and testing data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FRIJH8kztF39",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mS8JgU17tI0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a21cf563-4b36-42c7-ff9e-e167595f295d"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1078, 48)\n",
            "(719, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O5fHbaKjtLmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log1 = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8PTzaQhtSjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cf0b78c-c093-42a6-894f-4c4e3a7bf4ca"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "log1.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1451256275177002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-nXv-98Izguj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see here that fitting time reduced somewhat but the change is not that much evident beacuse the dataset that we are usiing is already beatifully cleaned and preprocessed that it does not take much time to it the all 64 dimensions altogether without doing any PCA.\n"
      ]
    },
    {
      "metadata": {
        "id": "BUN2AIErtWbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions1 = log1.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8qXIy2O1uHA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa136d80-b1ba-4521-b7ce-e19362ad1225"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy Score when doing logistic regression after applying PCA: ', accuracy_score(y_test, predictions1))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score when doing logistic regression after applying PCA:  0.9680111265646731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f3AqVlT30_xO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see here accuracy also doesn't changes much. So it's a better approach to do PCA on our features and then apply our algorithm onto it as it saves us our time and memory consumption."
      ]
    },
    {
      "metadata": {
        "id": "1F_7clns1-7S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION\n",
        "\n",
        "Principal Component Analysis is a better approach when dealing with Higher Dimensional Data as *Dimensionality reduction* helps us to get rid of *The curse of dimensionality*.\n",
        "\n",
        "Moreover, we can save our time and memory consumption.!"
      ]
    },
    {
      "metadata": {
        "id": "6IPo5bMA19rY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}